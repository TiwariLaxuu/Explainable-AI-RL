# Explainable-AI-RL

> A research-oriented repository exploring **Explainable AI (XAI)** techniques â€” with a focus on **SHAP** and **LIME** 


## ðŸ“Š Explainable AI (XAI) vs Explainable Reinforcement Learning (XRL)

| Feature               | Explainable AI (XAI)                              | Explainable Reinforcement Learning (XRL)           |
|----------------------|---------------------------------------------------|----------------------------------------------------|
| **Scope**            | Applies to all AI/ML models (supervised, unsupervised) | Focused specifically on reinforcement learning agents |
| **Output Explained** | Single predictions or classifications             | Sequence of actions and learned policies           |
| **Techniques**       | SHAP, LIME, GradCAM, feature importance           | Reward decomposition, saliency maps, policy trees  |
| **Focus**            | Interpretability of static model outputs          | Interpretability of dynamic, sequential decisions  |
| **Examples**         | Explaining cancer risk prediction, loan approval  | Explaining game moves, trading strategies, robot actions |

---

### âœ… Summary

- **XAI** aims to make AI models transparent and trustworthy to human users.
- **XRL** is a subdomain of XAI focused on explaining why RL agents act the way they do over time.

